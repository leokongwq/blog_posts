---
layout: post
comments: true
title: pythonå¤šè¿›ç¨‹ç®€ä»‹
date: 2017-08-11 22:21:07
tags:
- python
categories:
- python
---

### å‰è¨€

ç”±äºCPythonä¸­`GIL(Global Interpreter Lock)`å­˜åœ¨ï¼Œå¯¼è‡´Pythonå¤šçº¿ç¨‹çš„æ•ˆç‡é’ˆå¯¹CPUå¯†é›†å‹çš„åº”ç”¨ä¸å‹å¥½ã€‚å…·ä½“åŸå› å¯ä»¥å‚è€ƒä¼˜ç§€åšæ–‡:[Pythonçš„GILæ˜¯ä»€ä¹ˆé¬¼ï¼Œå¤šçº¿ç¨‹æ€§èƒ½ç©¶ç«Ÿå¦‚ä½•](http://cenalulu.github.io/python/gil-in-python/)ã€‚è§£å†³è¿™ä¸ªé—®é¢˜çš„åŠæ³•å¾ˆå¤šï¼Œæ¢ä¸€ä¸ªPythonè¿è¡Œç¯å¢ƒæˆ–è€…æ¢ä¸€ç§è¯­è¨€ã€‚å“ˆå“ˆ..... å½“ç„¶äº†ä½ ä¹Ÿå¯ä»¥ä½¿ç”¨`multiprocessing`

<!-- more -->


### multiprocessing ç®€ä»‹

> multiprocessing is a package that supports spawning processes using an API similar to the threading module. The multiprocessing package offers both local and remote concurrency, effectively side-stepping the Global Interpreter Lock by using subprocesses instead of threads. Due to this, the multiprocessing module allows the programmer to fully leverage multiple processors on a given machine. It runs on both Unix and Windows.

æ„æ€å°±æ˜¯è¯¥æ¨¡å—å¯ä»¥ç”¨æ¥ç”Ÿæˆå¤šä¸ªè¿›ç¨‹ï¼Œä»¥æ­¤æ¥é¿å…`GIL`çš„é™åˆ¶ï¼Œä»è€Œå…è®¸ç¨‹åºå‘˜æ›´å¥½çš„åˆ©ç”¨CPUèµ„æºã€‚è¯¥æ¨¡å—åŒæ—¶æ”¯æŒWindowså’ŒLinuxã€‚

The multiprocessing module also introduces APIs which do not have analogs in the threading module. A prime example of this is the Pool object which offers a convenient means of parallelizing the execution of a function across multiple input values, distributing the input data across processes (data parallelism). The following example demonstrates the common practice of defining such functions in a module so that child processes can successfully import that module. This basic example of data parallelism using Pool,

```python
from multiprocessing import Pool
import time

def f(x):
    time.sleep(20)
    return x*x

if __name__ == '__main__':
    p = Pool(5)
    print(p.map(f, [1, 2, 3]))
```

will print to standard output

```
[1, 4, 9]
```

`multiprocessing`æ¨¡å—æä¾›äº†è¿›ç¨‹æ± åŠŸèƒ½ã€‚ä¸Šé¢ä»£ç çš„åŠŸèƒ½æ˜¯ï¼š

1. åˆ›å»ºäº†å«æœ‰5ä¸ªè¿›ç¨‹çš„è¿›ç¨‹æ± å¯¹è±¡
2. å°†list=[1,2,3]ä½œä¸ºæ¯ä¸ªè¿›ç¨‹è®¡ç®—ä»»åŠ¡çš„è¾“å…¥å‚æ•°
3. å°†æ¯ä¸ªå­è¿›ç¨‹çš„è®¡ç®—ç»“æœæ±‡æ€»èµ·æ¥å¹¶è¿”å›ã€‚

ä¸ºäº†æ›´å¥½çš„æ¼”ç¤ºä»£ç çš„åŠŸèƒ½ï¼Œæˆ‘æ·»åŠ äº†`time.sleep(20)`è¯­å¥ã€‚æ‰§è¡Œä¸Šé¢çš„ä»£ç æˆ‘ä»¬å¯ä»¥çœ‹åˆ°ç³»ç»Ÿä¼šå­˜åœ¨å¤šä¸ªè¿›ç¨‹ã€‚å¦‚ä¸‹å›¾ï¼š

{% asset_img multi-processor.png %}

### Processç±»ç®€ä»‹

åœ¨`multiprocessing`åŒ…ä¸­ï¼Œåˆ›å»ºä¸€ä¸ªå­è¿›ç¨‹å…¶å®å°±æ˜¯åˆ›å»ºä¸€ä¸ª`Process`å¯¹è±¡ï¼Œå¹¶è°ƒç”¨åˆ›å»ºå¯¹è±¡çš„`start()`æ–¹æ³•ã€‚
`Process`æä¾›äº†å’Œ`threading.Thread`ä¸€è‡´çš„APIã€‚ä¸‹é¢å°±æ˜¯ä¸€ä¸ªå¤šè¿›ç¨‹çš„å°ä¾‹å­ï¼š

```python
from multiprocessing import Process

def f(name):
    print 'hello', name

if __name__ == '__main__':
    p = Process(target=f, args=('bob',))
    p.start()
    p.join()
```

ä¸Šé¢ä»£ç çš„ä½œç”¨å¦‚ä¸‹ï¼š

1. åˆ›å»ºä¸€ä¸ª`Process`å¯¹è±¡
2. è°ƒç”¨Processå¯¹è±¡çš„`start()`æ–¹æ³•
3. åœ¨ä¸»è¿›ç¨‹ä¸­ç­‰å¾…å­è¿›ç¨‹ç»“æŸ

ä¸‹é¢çš„ä»£ç æ¼”ç¤ºäº†å¦‚ä½•è·å–ä¸»å­è¿›ç¨‹çš„IDï¼š

```python
from multiprocessing import Process
import os

def info(title):
    print title
    print 'module name:', __name__
    if hasattr(os, 'getppid'):  # only available on Unix
        print 'parent process:', os.getppid()
    print 'process id:', os.getpid()

def f(name):
    info('function f')
    print 'hello', name

if __name__ == '__main__':
    info('main line')
    p = Process(target=f, args=('bob',))
    p.start()
    p.join()
```

### è¿›ç¨‹é—´äº¤æ¢æ•°æ®

`multiprocessing` æ”¯æŒä¸¤ç§è¿›ç¨‹é—´é€šä¿¡çš„é€šé“ï¼š

#### Queues

ç±»`Queue`ç±»ä¼¼`Queue.Queue`çš„ä¸€ä¸ªå…‹éš†ã€‚ä¸‹é¢çš„ä¾‹å­æ¼”ç¤ºäº†ä¸»å­è¿›ç¨‹é—´å¦‚ä½•é€šè¿‡`Queue`è¿›è¡Œé€šä¿¡ï¼š

```python
from multiprocessing import Process, Queue

def f(q):
    q.put([42, None, 'hello'])

if __name__ == '__main__':
    q = Queue()
    p = Process(target=f, args=(q,))
    p.start()
    print q.get()    # prints "[42, None, 'hello']"
    p.join()
```

Queue æ˜¯çº¿ç¨‹å’Œè¿›ç¨‹é—´å®‰å…¨çš„

#### Pipes

å‡½æ•°`Pipe()`è¿”å›ä¸€å¯¹é€šè¿‡é»˜è®¤å…¨åŒå·¥çš„`pipe`è¿›è¡Œé€šä¿¡çš„è¿æ¥å¯¹è±¡ã€‚

```python
from multiprocessing import Process, Pipe

def f(conn):
    conn.send([42, None, 'hello'])
    conn.close()

if __name__ == '__main__':
    parent_conn, child_conn = Pipe()
    p = Process(target=f, args=(child_conn,))
    p.start()
    print parent_conn.recv()   # prints "[42, None, 'hello']"
    p.join()
```

`Pipe()`è¿”å›çš„ä¸¤ä¸ªè¿æ¥å¯¹è±¡ä»£è¡¨äº†`pipe`çš„ä¸¤ç«¯ã€‚æ¯ä¸€ä¸ªè¿æ¥å¯¹è±¡éƒ½æœ‰ä¸€ä¸ª`send()`å’Œ`recv()`æ–¹æ³•ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼š`pipe`ä¸­çš„æ•°æ®æœ‰å¯èƒ½å˜çš„ä¸å¯ç”¨ï¼Œè¿™æ˜¯å¯èƒ½æ˜¯å› ä¸ºä¸¤ä¸ªè¿æ¥å¯¹è±¡åŒæ—¶åœ¨é€šé“çš„**ä¸€ç«¯**è¿›è¡Œè¯»å–æˆ–å†™å…¥æ“ä½œã€‚å½“ç„¶äº†åŒæ—¶åœ¨é€šé“çš„ä¸¤ç«¯è¿›è¡Œæ“ä½œæ˜¯æ²¡æœ‰ä»»ä½•é£é™©çš„ã€‚

### è¿›ç¨‹é—´åŒæ­¥

`multiprocessing`åŒ…å«äº†ä¸`threading`ä¸­æ‰€æœ‰åŒæ­¥å…ƒè¯­ç­‰ä»·çš„å®ç°ã€‚ä¸€ä¸ªä¾‹å­å°±æ˜¯ï¼šå¯ä»¥é€šè¿‡ä¸€ä¸ªğŸ”ç¡®ä¿åœ¨åŒä¸€æ—¶åˆ»åªèƒ½æœ‰ä¸€ä¸ªè¿›ç¨‹æ‰“å°æ•°æ®åˆ°æ ‡å‡†è¾“å‡ºã€‚

```python
from multiprocessing import Process, Lock

def f(l, i):
    l.acquire()
    print 'hello world', i
    l.release()

if __name__ == '__main__':
    lock = Lock()

    for num in range(10):
        Process(target=f, args=(lock, num)).start()
```

å¦‚æœæ²¡æœ‰åŒæ­¥ï¼Œæ‰€æœ‰è¿›ç¨‹çš„è¾“å‡ºå°†ä¼šæ˜¯ä¹±åºçš„ã€‚

### è¿›ç¨‹é—´å…±äº«çŠ¶æ€

å°±åƒä¸Šé¢æåˆ°çš„ï¼Œåœ¨å¹¶å‘ç¼–ç¨‹ä¸­æœ€å¥½å°½å¯èƒ½çš„é¿å…çŠ¶æ€å…±äº«ã€‚è¿™æ¡è§„åˆ™åŒæ ·é€‚ç”¨äºå¤šè¿›ç¨‹ã€‚ç„¶è€Œï¼Œå¦‚æœä½ å¿…é¡»åœ¨å¤šä¸ªè¿›ç¨‹é—´å…±äº«æ•°æ®ï¼Œ`multiprocessing`ä¹Ÿæä¾›äº†ä¸‹é¢çš„å‡ ç§æ–¹å¼æ¥å®ç°ã€‚

#### Shared memory

å…±äº«æ•°æ®å¯ä»¥ä½¿ç”¨`Value`æˆ–`Array`ä¿å­˜åœ¨å…±äº«å†…å­˜æ˜ å°„ä¸­ã€‚ä¾‹å¦‚ä¸‹é¢ä»£ç æ‰€ç¤ºï¼š

```python
from multiprocessing import Process, Value, Array

def f(n, a):
    n.value = 3.1415927
    for i in range(len(a)):
        a[i] = -a[i]

if __name__ == '__main__':
    num = Value('d', 0.0)
    arr = Array('i', range(10))

    p = Process(target=f, args=(num, arr))
    p.start()
    p.join()

    print num.value
    print arr[:]
```

è¾“å‡ºå¦‚ä¸‹ï¼š

```
3.1415927
[0, -1, -2, -3, -4, -5, -6, -7, -8, -9]
```

ä¸Šé¢ä»£ç ä¸­ï¼Œåˆ›å»ºå˜é‡numå’Œå˜é‡arrä½¿ç”¨çš„å‚æ•°`d`,`i`éƒ½æ˜¯ç±»å‹ä»£ç ã€‚åœ¨æ•°ç»„ä¸­ä½¿ç”¨æ—¶ï¼Œ`d`è¡¨ç¤ºåŒç²¾åº¦çš„æµ®ç‚¹æ•°ï¼Œ`i`è¡¨ç¤ºæœ‰ç¬¦å·çš„æ•´æ•°ç±»å‹ã€‚è¿™äº›å˜é‡åœ¨ä½¿ç”¨æ—¶éƒ½æ˜¯çº¿ç¨‹å®‰å…¨çš„ã€‚

å¦‚æœéœ€è¦æ›´åŠ çµæ´»çš„ä½¿ç”¨å…±äº«å†…å­˜, å¯ä»¥ä½¿ç”¨`multiprocessing.sharedctypes`æ¨¡å—ï¼Œè¯¥æ¨¡å—æ”¯æŒåœ¨å…±äº«å†…å­˜ä¸­åˆ›å»ºä»»æ„çš„å¯¹è±¡ã€‚

#### Server process

ä¸€ä¸ª`Manager()`å‡½æ•°è¿”å›çš„managerå¯¹è±¡å¯ä»¥æ§åˆ¶ä¸€ä¸ªæ‹¥æœ‰pythonå¯¹è±¡çš„æœåŠ¡å™¨è¿›ç¨‹ï¼Œå¹¶å…è®¸å…¶å®ƒçš„è¿›ç¨‹ä½¿ç”¨ä»£ç†æ¥ä¿®æ”¹è¿™å†™Pythonå¯¹è±¡ã€‚

`Manager()`å‡½æ•°è¿”å›çš„å¯¹è±¡æ”¯æŒçš„ç±»å‹æœ‰: list, dict, Namespace, Lock, RLock, Semaphore, BoundedSemaphore, Condition, Event, Queue, Value and Arrayã€‚ä¸¾ä¸ªä¾‹å­ï¼š

```python
from multiprocessing import Process, Manager

def f(d, l):
    d[1] = '1'
    d['2'] = 2
    d[0.25] = None
    l.reverse()

if __name__ == '__main__':
    manager = Manager()

    d = manager.dict()
    l = manager.list(range(10))

    p = Process(target=f, args=(d, l))
    p.start()
    p.join()

    print d
    print l
```

è¾“å‡ºå¦‚ä¸‹ï¼š

```
{0.25: None, 1: '1', '2': 2}
[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]
```

æœåŠ¡å™¨è¿›ç¨‹ç®¡ç†å™¨æ¯”ä½¿ç”¨å…±äº«å†…å­˜å¯¹è±¡æ›´çµæ´»ï¼Œå› ä¸ºå®ƒä»¬å¯ä»¥ç”¨äºæ”¯æŒä»»æ„å¯¹è±¡ç±»å‹ã€‚ æ­¤å¤–ï¼Œå•ä¸ªç®¡ç†å™¨å¯ä»¥é€šè¿‡ç½‘ç»œåœ¨ä¸åŒè®¡ç®—æœºä¸Šçš„è¿›ç¨‹å…±äº«ã€‚ ä½†æ˜¯ï¼Œå®ƒä»¬æ¯”ä½¿ç”¨å…±äº«å†…å­˜è¦æ…¢ã€‚

### Using a pool of workers

ç±»`Pool`è¡¨ç¤ºä¸€ä¸ªå·¥ä½œè¿›ç¨‹æ± ã€‚ å®ƒå…·æœ‰å‡ ç§ä¸åŒæ–¹æ³•å°†ä»»åŠ¡åˆ†é…åˆ°å·¥ä½œè¿›ç¨‹ä¸Šã€‚

For example:

```python
from multiprocessing import Pool, TimeoutError
import time
import os

def f(x):
    return x*x

if __name__ == '__main__':
    pool = Pool(processes=4)              # start 4 worker processes

    # print "[0, 1, 4,..., 81]"
    print pool.map(f, range(10))

    # print same numbers in arbitrary order
    for i in pool.imap_unordered(f, range(10)):
        print i

    # evaluate "f(20)" asynchronously
    res = pool.apply_async(f, (20,))      # runs in *only* one process
    print res.get(timeout=1)              # prints "400"

    # evaluate "os.getpid()" asynchronously
    res = pool.apply_async(os.getpid, ()) # runs in *only* one process
    print res.get(timeout=1)              # prints the PID of that process

    # launching multiple evaluations asynchronously *may* use more processes
    multiple_results = [pool.apply_async(os.getpid, ()) for i in range(4)]
    print [res.get(timeout=1) for res in multiple_results]

    # make a single worker sleep for 10 secs
    res = pool.apply_async(time.sleep, (10,))
    try:
        print res.get(timeout=1)
    except TimeoutError:
        print "We lacked patience and got a multiprocessing.TimeoutError"
```

**è¯·æ³¨æ„**ï¼Œ`Pool`ç±»å¯¹è±¡çš„æ–¹æ³•åªèƒ½ç”±åˆ›å»ºå®ƒçš„è¿›ç¨‹ä½¿ç”¨ã€‚

> æ­¤åŒ…ä¸­çš„åŠŸèƒ½è¦æ±‚__main__æ¨¡å—å¯ç”±å­çº§å¯¼å…¥ã€‚ è¿™åœ¨ç¼–ç¨‹æŒ‡å—ä¸­æœ‰æ‰€æ¶‰åŠï¼Œä½†å€¼å¾—ä¸€æçš„æ˜¯è¿™é‡Œã€‚ è¿™æ„å‘³ç€ä¸€äº›ç¤ºä¾‹ï¼Œä¾‹å¦‚Poolç¤ºä¾‹å°†æ— æ³•åœ¨äº¤äº’å¼è§£é‡Šå™¨ä¸­ä½¿ç”¨ã€‚ ä¾‹å¦‚ï¼š
```
>>> from multiprocessing import Pool
>>> p = Pool(5)
>>> def f(x):
...     return x*x
...
>>> p.map(f, [1,2,3])
Process PoolWorker-1:
Process PoolWorker-2:
Process PoolWorker-3:
Traceback (most recent call last):
AttributeError: 'module' object has no attribute 'f'
AttributeError: 'module' object has no attribute 'f'
AttributeError: 'module' object has no attribute 'f'
```
(å¦‚æœä½ å°è¯•è¿™æ ·åšï¼Œå®é™…ä¸Šå®ƒä¼šåŠéšæœºçš„è¾“å‡ºä¸‰ä¸ªå®Œæ•´çš„å †æ ˆä¿¡æ¯ï¼Œ ç„¶åä½ å¯èƒ½ä¸å¾—ä¸åœæ­¢ä¸»è¿›ç¨‹ã€‚)
    
### å‚è€ƒ

[https://docs.python.org/2/library/multiprocessing.html](https://docs.python.org/2/library/multiprocessing.html)



